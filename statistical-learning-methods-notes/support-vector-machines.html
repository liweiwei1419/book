<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>《统计学习方法》第 7 章“支持向量机”学习笔记 | 算法不好玩</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/book/logo.png">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.7.1/katex.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/github-markdown-css/2.10.0/github-markdown.min.css">
    <meta name="description" content="">
    
    <link rel="preload" href="/book/assets/css/0.styles.e159a327.css" as="style"><link rel="preload" href="/book/assets/js/app.a4355b0d.js" as="script"><link rel="preload" href="/book/assets/js/2.ba785ee6.js" as="script"><link rel="preload" href="/book/assets/js/48.9bb76138.js" as="script"><link rel="prefetch" href="/book/assets/js/10.b6950be1.js"><link rel="prefetch" href="/book/assets/js/11.f4ee7d6e.js"><link rel="prefetch" href="/book/assets/js/12.50fe1ace.js"><link rel="prefetch" href="/book/assets/js/13.42356fcc.js"><link rel="prefetch" href="/book/assets/js/14.e740c742.js"><link rel="prefetch" href="/book/assets/js/15.05c628f7.js"><link rel="prefetch" href="/book/assets/js/16.bd9bc9d5.js"><link rel="prefetch" href="/book/assets/js/17.e120b4fc.js"><link rel="prefetch" href="/book/assets/js/18.398213f8.js"><link rel="prefetch" href="/book/assets/js/19.e29ad0b2.js"><link rel="prefetch" href="/book/assets/js/20.14e30c1c.js"><link rel="prefetch" href="/book/assets/js/21.4f05f6c9.js"><link rel="prefetch" href="/book/assets/js/22.98fbf199.js"><link rel="prefetch" href="/book/assets/js/23.285387f4.js"><link rel="prefetch" href="/book/assets/js/24.852addbe.js"><link rel="prefetch" href="/book/assets/js/25.d30ade13.js"><link rel="prefetch" href="/book/assets/js/26.23dfa040.js"><link rel="prefetch" href="/book/assets/js/27.b6eae7df.js"><link rel="prefetch" href="/book/assets/js/28.97878b08.js"><link rel="prefetch" href="/book/assets/js/29.7217a3d0.js"><link rel="prefetch" href="/book/assets/js/3.f0c15194.js"><link rel="prefetch" href="/book/assets/js/30.0ced5a5a.js"><link rel="prefetch" href="/book/assets/js/31.8f432033.js"><link rel="prefetch" href="/book/assets/js/32.aac9aa62.js"><link rel="prefetch" href="/book/assets/js/33.db835477.js"><link rel="prefetch" href="/book/assets/js/34.a1a59c2a.js"><link rel="prefetch" href="/book/assets/js/35.ed2ef96b.js"><link rel="prefetch" href="/book/assets/js/36.48099c55.js"><link rel="prefetch" href="/book/assets/js/37.32827612.js"><link rel="prefetch" href="/book/assets/js/38.58abec0e.js"><link rel="prefetch" href="/book/assets/js/39.f6eb3874.js"><link rel="prefetch" href="/book/assets/js/4.13ea3b32.js"><link rel="prefetch" href="/book/assets/js/40.80523ed8.js"><link rel="prefetch" href="/book/assets/js/41.f7b72b7a.js"><link rel="prefetch" href="/book/assets/js/42.44e40de9.js"><link rel="prefetch" href="/book/assets/js/43.065f077f.js"><link rel="prefetch" href="/book/assets/js/44.386d9aea.js"><link rel="prefetch" href="/book/assets/js/45.d8a88f16.js"><link rel="prefetch" href="/book/assets/js/46.33bc2083.js"><link rel="prefetch" href="/book/assets/js/47.e7767237.js"><link rel="prefetch" href="/book/assets/js/49.c2ca5c29.js"><link rel="prefetch" href="/book/assets/js/5.32eda204.js"><link rel="prefetch" href="/book/assets/js/50.1242fe24.js"><link rel="prefetch" href="/book/assets/js/51.e8f8117d.js"><link rel="prefetch" href="/book/assets/js/52.eae5648f.js"><link rel="prefetch" href="/book/assets/js/53.39876d83.js"><link rel="prefetch" href="/book/assets/js/6.1c662163.js"><link rel="prefetch" href="/book/assets/js/7.29470445.js"><link rel="prefetch" href="/book/assets/js/8.814b737f.js"><link rel="prefetch" href="/book/assets/js/9.d4211262.js">
    <link rel="stylesheet" href="/book/assets/css/0.styles.e159a327.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/book/" class="home-link router-link-active"><!----> <span class="site-name">算法不好玩</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/book/" class="nav-link">
  主页
</a></div><div class="nav-item"><a href="/book/guide/" class="nav-link">
  关于我
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="基础算法与数据结构" class="dropdown-title"><span class="title">基础算法与数据结构</span> <span class="arrow down"></span></button> <button type="button" aria-label="基础算法与数据结构" class="mobile-dropdown-title"><span class="title">基础算法与数据结构</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          排序算法
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/book/algs/01-binary-search/" class="nav-link">
  第 1 章 二分查找
</a></li><li class="dropdown-subitem"><a href="/book/algs/recursion/" class="nav-link">
  第 2 章 递归
</a></li></ul></li><li class="dropdown-item"><h4>
          数组里的算法
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/book/algs/01-binary-search/" class="nav-link">
  第 4 章 滑动窗口
</a></li><li class="dropdown-subitem"><a href="/book/algs/02-basic-sorting/" class="nav-link">
  第 5 章 双指针
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="威威道来" class="dropdown-title"><span class="title">威威道来</span> <span class="arrow down"></span></button> <button type="button" aria-label="威威道来" class="mobile-dropdown-title"><span class="title">威威道来</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/book/talk-show/2021-04/" class="nav-link">
  2021 年 4 月
</a></li></ul></div></div><div class="nav-item"><a href="https://leetcode-cn.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  力扣
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://gitee.com/liweiwei1419/book/pages" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Gitee 部署页面
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/book/" class="nav-link">
  主页
</a></div><div class="nav-item"><a href="/book/guide/" class="nav-link">
  关于我
</a></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="基础算法与数据结构" class="dropdown-title"><span class="title">基础算法与数据结构</span> <span class="arrow down"></span></button> <button type="button" aria-label="基础算法与数据结构" class="mobile-dropdown-title"><span class="title">基础算法与数据结构</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><h4>
          排序算法
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/book/algs/01-binary-search/" class="nav-link">
  第 1 章 二分查找
</a></li><li class="dropdown-subitem"><a href="/book/algs/recursion/" class="nav-link">
  第 2 章 递归
</a></li></ul></li><li class="dropdown-item"><h4>
          数组里的算法
        </h4> <ul class="dropdown-subitem-wrapper"><li class="dropdown-subitem"><a href="/book/algs/01-binary-search/" class="nav-link">
  第 4 章 滑动窗口
</a></li><li class="dropdown-subitem"><a href="/book/algs/02-basic-sorting/" class="nav-link">
  第 5 章 双指针
</a></li></ul></li></ul></div></div><div class="nav-item"><div class="dropdown-wrapper"><button type="button" aria-label="威威道来" class="dropdown-title"><span class="title">威威道来</span> <span class="arrow down"></span></button> <button type="button" aria-label="威威道来" class="mobile-dropdown-title"><span class="title">威威道来</span> <span class="arrow right"></span></button> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/book/talk-show/2021-04/" class="nav-link">
  2021 年 4 月
</a></li></ul></div></div><div class="nav-item"><a href="https://leetcode-cn.com/" target="_blank" rel="noopener noreferrer" class="nav-link external">
  力扣
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div><div class="nav-item"><a href="https://gitee.com/liweiwei1419/book/pages" target="_blank" rel="noopener noreferrer" class="nav-link external">
  Gitee 部署页面
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></div> <!----></nav>  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><div class="custom-block tip"><p class="custom-block-title">TIP</p> <p>本文介绍了支持向量机。</p> <p>关键字：函数间隔、几何间隔、正则化的合页损失函数、凸二次规划、核技巧（核函数）、输入空间、特征空间、欧式空间、希尔伯特空间。</p></div> <p>我这篇笔记主要是介绍李航的《统计学习方法》第 7 章内容，以笔记的方式呈现。需要说明的是，为了使得本文尽量易懂，我把书上的一些标题或者专有名词做了更改，只是为了帮助初学的朋友们的理解。</p> <h3 id="svm-的思想-从感知机开始"><a href="#svm-的思想-从感知机开始" class="header-anchor">#</a> SVM 的思想，从感知机开始</h3> <p>1、研究基础：感知机，二分类问题，并且数据是线性可分的；</p> <p>感知机的缺点：数据集必须线性可分。如果数据集不能线性可分，（在不限制迭代次数的情况下），算法无法收敛。</p> <p>2、感知机的决策边界是不唯一的，而 SVM 得到的决策边界唯一；</p> <p>3、感知机对数据不能线性可分的情况下，它的训练不收敛，而 SVM 更多地考虑到了<strong>模型的泛化能力，对于未知的数据， SVM 有更好的预测能力</strong>；</p> <p>比较下面两张图，我们认为数据点应该尽量远离决策边界，这是我们指定严格线性可分支持向量机的学习准则，即策略，<strong>因为如果数据点距离决策边界很近，决策边界的一点点改动，都会造成一些数据点的预测类别改变，这是不稳定的</strong>。</p> <p>说明：这里“硬间隔”对应了我前面说的“严格线性可分”，是相对于后面叙述的“软间隔”而言的，可以看到软间隔的时候，再来理解这一点。</p> <p>4、SVM 尝试寻找一个最优的决策边界，这个决策边界<strong>距离两个类别“最近的样本”足够远，并且考虑到模型的泛化能力，允许不分点分错（soft margin）</strong>；</p> <p>5、一些重要的概念：支持向量（距离决策边界最近的那些点）；寻找到的决策边界是分离超平面；margin = 2d。</p> <h3 id="研究思路"><a href="#研究思路" class="header-anchor">#</a> 研究思路</h3> <p>1、最大化间隔（soft margin 其实就是正则化，参数 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="C"></mjx-c></mjx-mi></mjx-math></mjx-container> 控制松弛因子）；</p> <p>2、转化成最优化问题的标准格式（注意：此时是有约束的）；</p> <p>3、使用拉格朗日乘子法把约束去掉；</p> <p>4、转向拉格朗日对偶问题；我们本来的目标是求 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi></mjx-math></mjx-container> 和 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi></mjx-math></mjx-container>，但是我们转向求 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3B1"></mjx-c></mjx-mi></mjx-math></mjx-container> 了，通过求得的 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3B1"></mjx-c></mjx-mi></mjx-math></mjx-container>，得到 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi></mjx-math></mjx-container> 和 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi></mjx-math></mjx-container> 的表达式。</p> <p>5、使用 SMO 解决这个问题，我们发现， <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi></mjx-math></mjx-container> 和 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi></mjx-math></mjx-container> 只由部分支持向量决定，即拉格朗日引入的参数里，很多都是 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mn class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-math></mjx-container>；</p> <p>6、为了处理非线性问题，我们引入了核函数（相似性函数）：</p> <p>低维度不能线性可分，高维度可以线性可分，这是研究的基本思路；</p> <p>升维以后，计算量巨大，为了解决这个问题，引入了核函数，使得我们的计算不必放到高维空间去计算；</p> <p>常用的核函数有：线性核函数、多项式核函数、高斯核函数。</p> <p>线性不可分有两种策略：1、软间隔：允许一些点分错；2、核函数。</p> <h3 id="可以取函数间隔等于-1-是为什么"><a href="#可以取函数间隔等于-1-是为什么" class="header-anchor">#</a> 可以取函数间隔等于 1 是为什么</h3> <p>我看到这一部分觉得比较难理解的是，怎么就把最后的目标函数，即两条间隔边界的距离变成</p>
{\max_{w,b}} \quad \cfrac{1}{||w||}

<p>书上怎么就莫名其妙取 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.009em;margin-bottom:-0.531em;"><mjx-mo class="mjx-n"><mjx-c c="^"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="3B3"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-math></mjx-container>，然后得到线性可分的支持向量机的最优化问题</p>
\begin{aligned}
{\rm \min_{w,b}} \quad &amp; \cfrac{1}{2}||w||^2 \\
{\rm s.t.} \quad &amp; y_i(w \cdot x_i+b) - 1\geq 0, \quad i = 1, 2, \cdots,N
\end{aligned}

<p>假设两条平行直线分别是：</p>
Wx+A=0,\tag{1}

<p>与</p>
Wx+B=0.\tag{2}

<p>那么和这两条直线平行，且位于中间的那条直线就可以表示成：</p>
Wx + A + \frac{B-A}{2} = 0.
\tag{3}

<p>令 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="t"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mi space="4" class="mjx-i"><mjx-c c="B"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="A"></mjx-c></mjx-mi></mjx-math></mjx-container>，则有 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="B"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mi space="4" class="mjx-i"><mjx-c c="t"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="A"></mjx-c></mjx-mi></mjx-math></mjx-container>。将 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="t"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mi space="4" class="mjx-i"><mjx-c c="B"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="A"></mjx-c></mjx-mi></mjx-math></mjx-container> 代入（3），得到</p>
Wx+A+\frac{t}{2}=0.\tag{4}

<p>将 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="B"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mi space="4" class="mjx-i"><mjx-c c="t"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="A"></mjx-c></mjx-mi></mjx-math></mjx-container> 代入（2），得到</p>
Wx+t+A=0.\tag{5}

<p>整理一下，这三条直线现在可以写成</p>
Wx+A=0,\tag{6}

Wx+t+A=0,\tag{7}

Wx+A+\frac{t}{2}=0.\tag{8}

<p>下面给（6）左右都加上 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mpadded><mjx-block style="margin:0.896em 0 0.313em;"><mjx-mrow></mjx-mrow></mjx-block></mjx-mpadded><mjx-mstyle style="font-size:141.4%;"><mjx-TeXAtom><mjx-mi class="mjx-i"><mjx-c c="t"></mjx-c></mjx-mi></mjx-TeXAtom></mjx-mstyle></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mpadded><mjx-block style="margin:0.896em 0 0.313em;"><mjx-mrow></mjx-mrow></mjx-block></mjx-mpadded><mjx-mstyle style="font-size:141.4%;"><mjx-TeXAtom><mjx-mn class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-mstyle></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math></mjx-container>，给（7）左右都减去 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mpadded><mjx-block style="margin:0.896em 0 0.313em;"><mjx-mrow></mjx-mrow></mjx-block></mjx-mpadded><mjx-mstyle style="font-size:141.4%;"><mjx-TeXAtom><mjx-mi class="mjx-i"><mjx-c c="t"></mjx-c></mjx-mi></mjx-TeXAtom></mjx-mstyle></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mpadded><mjx-block style="margin:0.896em 0 0.313em;"><mjx-mrow></mjx-mrow></mjx-block></mjx-mpadded><mjx-mstyle style="font-size:141.4%;"><mjx-TeXAtom><mjx-mn class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-mstyle></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math></mjx-container>，得到</p>
Wx+A+\frac{t}{2}=\frac{t}{2},\tag{9}

<p>与</p>
Wx+A+\frac{t}{2}=-\frac{t}{2}.\tag{10}

<p>接下来将等式（8）、（9）、（10）的两边都乘以 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mi size="s" class="mjx-i"><mjx-c c="t"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac></mjx-math></mjx-container>，得</p>
\cfrac{2}{t}Wx+\cfrac{2}{t}(A+\cfrac{t}{2})=0,\tag{11}

\cfrac{2}{t}Wx+\cfrac{2}{t}(A+\cfrac{t}{2})=1,\tag{12}

\cfrac{2}{t}Wx+\cfrac{2}{t}(A+\cfrac{t}{2})=-1.\tag{13}

<p>令 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mi size="s" class="mjx-i"><mjx-c c="t"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mi class="mjx-i"><mjx-c c="W"></mjx-c></mjx-mi></mjx-math></mjx-container>，<mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mfrac space="4"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mi size="s" class="mjx-i"><mjx-c c="t"></mjx-c></mjx-mi></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="A"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-mfrac space="3"><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mi size="s" class="mjx-i"><mjx-c c="t"></mjx-c></mjx-mi></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container>，则等式（11）、等式（12）、等式（13）又可以写成：</p>
wx+b=0,\tag{14}

wx+b=1,\tag{15}

wx+b=-1.\tag{16}

<p>化简成这样的主要原因是，间隔（margin）的表达式最简单。</p> <p>可以假设向量 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math></mjx-container> 在 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-math></mjx-container> 上，向量 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math></mjx-container> 在 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-math></mjx-container> 上，间隔（margin）的表达式为</p>
margin = d = |x_1-x_2|\cdot \cos \theta.\tag{17}

<p>其中 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="3B8"></mjx-c></mjx-mi></mjx-math></mjx-container> 是向量 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub><mjx-mo space="3" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-msub space="3"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math></mjx-container> 与平行直线的法向量 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi></mjx-math></mjx-container> 的夹角。为了利用向量的工具，我们可以在等式（17）两边都乘以 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mo class="mjx-n"><mjx-c c="|"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="|"></mjx-c></mjx-mo></mjx-math></mjx-container>，则有</p>
d\cdot |w| = |x_1-x_2| \cdot |w| \cdot \cos \theta = |w(x1-x2)| .\tag{18}

<p>又因为向量 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math></mjx-container> 在 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-math></mjx-container> 上，向量 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math></mjx-container> 在 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi><mjx-mo space="3" class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-mi space="3" class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-mo space="4" class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mo space="4" class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-math></mjx-container> 上，则</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><msub><mi>x</mi><mn>1</mn></msub><mo>+</mo><mi>b</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">wx_1+b=1,
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">+</span><span class="mord mathit">b</span><span class="mrel">=</span><span class="mord mathrm">1</span><span class="mpunct">,</span></span></span></span></span></p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><msub><mi>x</mi><mn>2</mn></msub><mo>+</mo><mi>b</mi><mo>=</mo><mo>−</mo><mn>1</mn><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">wx_2+b=-1.
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">+</span><span class="mord mathit">b</span><span class="mrel">=</span><span class="mord">−</span><span class="mord mathrm">1</span><span class="mord mathrm">.</span></span></span></span></span></p> <p>所以</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi mathvariant="normal">∣</mi><mi>w</mi><mo>(</mo><mi>x</mi><mn>1</mn><mo>−</mo><mi>x</mi><mn>2</mn><mo>)</mo><mi mathvariant="normal">∣</mi><mo>=</mo><mi mathvariant="normal">∣</mi><mi>w</mi><msub><mi>x</mi><mn>1</mn></msub><mo>−</mo><mi>w</mi><msub><mi>x</mi><mn>2</mn></msub><mi mathvariant="normal">∣</mi><mo>=</mo><mi mathvariant="normal">∣</mi><mn>1</mn><mo>−</mo><mi>b</mi><mo>−</mo><mo>(</mo><mo>−</mo><mn>1</mn><mo>−</mo><mi>b</mi><mo>)</mo><mi mathvariant="normal">∣</mi><mo>=</mo><mn>2</mn><mo>=</mo><mi>d</mi><mo>⋅</mo><mi mathvariant="normal">∣</mi><mi>w</mi><mi mathvariant="normal">∣</mi><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">|w(x1-x2)|=|wx_1-wx_2|=|1-b-(-1-b)|=2=d\cdot |w|.
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.75em;"></span><span class="strut bottom" style="height:1em;vertical-align:-0.25em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathrm">∣</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mopen">(</span><span class="mord mathit">x</span><span class="mord mathrm">1</span><span class="mbin">−</span><span class="mord mathit">x</span><span class="mord mathrm">2</span><span class="mclose">)</span><span class="mord mathrm">∣</span><span class="mrel">=</span><span class="mord mathrm">∣</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">−</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mord mathrm">∣</span><span class="mrel">=</span><span class="mord mathrm">∣</span><span class="mord mathrm">1</span><span class="mbin">−</span><span class="mord mathit">b</span><span class="mbin">−</span><span class="mopen">(</span><span class="mord">−</span><span class="mord mathrm">1</span><span class="mbin">−</span><span class="mord mathit">b</span><span class="mclose">)</span><span class="mord mathrm">∣</span><span class="mrel">=</span><span class="mord mathrm">2</span><span class="mrel">=</span><span class="mord mathit">d</span><span class="mbin">⋅</span><span class="mord mathrm">∣</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mord mathrm">∣</span><span class="mord mathrm">.</span></span></span></span></span></p> <p>所以</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mo>=</mo><mfrac><mrow><mn>2</mn></mrow><mrow><mi mathvariant="normal">∣</mi><mi>w</mi><mi mathvariant="normal">∣</mi></mrow></mfrac><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">d = \frac{2}{|w|}.
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:1.32144em;"></span><span class="strut bottom" style="height:2.25744em;vertical-align:-0.936em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit">d</span><span class="mrel">=</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.686em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mord mathrm">∣</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mord mathrm">∣</span></span></span></span><span style="top:-0.2300000000000001em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">2</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mord mathrm">.</span></span></span></span></span></p> <p>手写笔记如下：</p> <p><img src="http://upload-images.jianshu.io/upload_images/414598-bd27b5178f9769b5.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> <p><img src="http://upload-images.jianshu.io/upload_images/414598-c2ce3fa3c84a92c1.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> <p><img src="http://upload-images.jianshu.io/upload_images/414598-64742b7562a3630a.jpg?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240" alt=""></p> <h3 id="学习-支持向量机-的步骤"><a href="#学习-支持向量机-的步骤" class="header-anchor">#</a> 学习“支持向量机”的步骤</h3> <p>“支持向量机”的内容非常多，掌握“支持向量机”是要花费一定时间的，经常看着看着，就不知道自己在看啥了。下面我简单罗列一下关于“支持向量机”的研究顺序，和各个知识点的地位和作用，希望能给看到我这篇笔记的朋友们一些帮助。</p> <blockquote><p>&quot;支持向量机&quot;学习方法包含构建由简单到复杂的模型。</p> <p>—— 李航《统计学习方法》第 7 章“支持向量机”引言部分。</p></blockquote> <p>由简单到复杂的模型依次就是下面 3 个模型，我从统计学习 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mn class="mjx-n"><mjx-c c="3"></mjx-c></mjx-mn></mjx-math></mjx-container> 要素的角度（模型、策略、方法，李航《统计学习方法》第 1 章就有介绍）对它们再做一层剖析。</p> <h3 id="第-1-阶段-严格线性可分支持向量机"><a href="#第-1-阶段-严格线性可分支持向量机" class="header-anchor">#</a> 第 1 阶段：严格线性可分支持向量机</h3> <p>“严格线性可分支持向量机”即书上说的“线性可分支持向量机”。我这里强调“严格”是为了突出我们此时对模型的假设，这个假设和感知机模型是完全一致的。</p> <p>注：感知机模型是李航的《统计学习方法》介绍的第 1 个模型，麻雀虽小五脏俱全，我个人认为还是非常重要的，虽然很简单（那是在我了解他以后才觉得），在实际做分类的时候不会用它，但感知机模型从模型假设（线性可分）、到找到策略（损失函数最小化）、到使用方法（随机梯度下降法），比较完整清晰地体现了机器学习研究的基本步骤，并且感知机模型中提到的一些概念，例如线性可分、超平面、超平面的法向量、点到超平面的距离公式，定义类标为 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mo class="mjx-n"><mjx-c c="2212"></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-math></mjx-container> 和 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-math></mjx-container>，使用类标乘以预测结果表示预测正确与否，这些思想和技巧在支持向量机都可以看到，甚至感知机也有对偶问题的算法（对偶问题的算法提出就是为了方便计算，将参数的学习归结为部分样本数据特征和标签的线性组合，二者在这点上也是非常一致的），这一点也是极其相似的，因此，在学习支持向量机的时候，感知机如果你忘了的话，可以趁机复习一下。</p> <p>后一个模型“差一点线性可分的支持向量机”就可以通过引入一个容忍错误的度量，和严格线性可分的情况使用相同的“策略”和“方法”完成分类任务。</p> <p>具体，我们在看第 2 部分“线性支持向量机”的时候，其实可以看到，很多地方都是在摘抄第 1 部分的结论，在一些边界条件和目标函数上稍有不同而已，第 1 部分搞懂了，第 2 部分就非常快了。</p> <p>前面会跟你扯一些“代数间隔”、“几何间隔”的概念，我个人觉得不太重要，回过头来看都不要紧，介绍这两个概念无非是要保证后续叙述的无比正确性，这是写数学专著的要求；</p> <p>策略：策略这部分是很重要的，策略如果你忘了是什么，翻到书本第 1 章看看策略是什么，“硬间隔最大化”是核心思想，策略就是学习的准则，在“严格线性可分”的前提下，“硬间隔最大化”保证了模型有更好的泛化能力，即对未知数据的预测能力。</p> <p><img src="https://ws2.sinaimg.cn/large/006tKfTcly1g0mx3935lsj312o0u0wmk.jpg" alt=""></p> <p>“硬间隔最大化的支持向量机”问题最终转换成了数学问题，我们解这个最优化问题：</p>
{\rm \min_{w,b}} \qquad \cfrac{1}{2}||w||^2 \\
{\rm s.t.} \qquad y_i(w \cdot x_i+b) - 1\geq 0, \quad i = 1, 2, \cdots,N

<p>输入是严格线性可分的数据对 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mo class="mjx-n"><mjx-c c="("></mjx-c></mjx-mo><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.064em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo class="mjx-n"><mjx-c c=","></mjx-c></mjx-mo><mjx-mi space="2" class="mjx-i"><mjx-c c="y"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c=")"></mjx-c></mjx-mo></mjx-math></mjx-container>，输出是这个问题的最优解 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mo size="s" class="mjx-n"><mjx-c c="2217"></mjx-c></mjx-mo></mjx-script></mjx-msup></mjx-math></mjx-container> 和 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-mo size="s" class="mjx-n"><mjx-c c="2217"></mjx-c></mjx-mo></mjx-script></mjx-msup></mjx-math></mjx-container>。然后最优超平面就得到了：</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>w</mi><mo>∗</mo></msup><mo>⋅</mo><mover accent="true"><mi>x</mi><mo>⃗</mo></mover><mo>+</mo><msup><mi>b</mi><mo>∗</mo></msup><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">w^* \cdot \vec x + b^* = 0
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:0.738696em;"></span><span class="strut bottom" style="height:0.822026em;vertical-align:-0.08333em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="vlist"><span style="top:-0.413em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord">∗</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">⋅</span><span class="mord accent"><span class="vlist"><span style="top:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord mathit">x</span></span><span style="top:0em;margin-left:0.05556em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="accent-body accent-vec"><span>⃗</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">+</span><span class="mord"><span class="mord mathit">b</span><span class="vlist"><span style="top:-0.413em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord">∗</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">0</span></span></span></span></span></p> <p>做预测的时候把 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-TeXAtom><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.064em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom></mjx-math></mjx-container> 代入 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msup><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-TeXAtom size="s"><mjx-mo class="mjx-n"><mjx-c c="2217"></mjx-c></mjx-mo></mjx-TeXAtom></mjx-script></mjx-msup><mjx-mo space="3" class="mjx-n"><mjx-c c="22C5"></mjx-c></mjx-mo><mjx-TeXAtom space="3"><mjx-mover><mjx-over style="padding-bottom:0.06em;padding-left:0.064em;margin-bottom:-0.516em;"><mjx-mo class="mjx-n"><mjx-c c="20D7"></mjx-c></mjx-mo></mjx-over><mjx-base><mjx-mi class="mjx-i"><mjx-c c="x"></mjx-c></mjx-mi></mjx-base></mjx-mover></mjx-TeXAtom><mjx-mo space="3" class="mjx-n"><mjx-c c="+"></mjx-c></mjx-mo><mjx-msup space="3"><mjx-mi class="mjx-i"><mjx-c c="b"></mjx-c></mjx-mi><mjx-script style="vertical-align:0.363em;"><mjx-TeXAtom size="s"><mjx-mo class="mjx-n"><mjx-c c="2217"></mjx-c></mjx-mo></mjx-TeXAtom></mjx-script></mjx-msup></mjx-math></mjx-container> 判断符号，大于 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mn class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-math></mjx-container> 的归为一类，小于 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mn class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-math></mjx-container> 的归为另一类。</p> <p><strong>看到这里，其实我觉得可以先跳过书本的一些部分，直接到 7.2 节“线性支持向量机与软间隔最大化”。因为其实你已经知道”支持向量机“在做什么了。最起码它能解决严格线性可分的二分类数据问题。比起感知机而言，它得到的决策边界是唯一的，并且是对未知数据有很好的预测能力</strong>。</p> <p>在这个问题里，模型和感知机是一样的，即二分类数据“严格”线性可分，策略是“硬间隔最大化”，这一点用数学表达成能表示成如下形式：</p>
{\rm \min_{w,b}} \qquad \cfrac{1}{2}||w||^2 \\
{\rm s.t.} \qquad y_i(w \cdot x_i+b) - 1\geq 0, \quad i = 1, 2, \cdots,N

<p>看到这里，你可能会问：</p> <p>1、感知机只要分类都正确算法就停止了，它得到的决策边界是不唯一的；那么支持向量机得到的泛化性能比感知机好，你说它决策边界是唯一的，有什么证据吗？</p> <p>答：当然有啦，就是书本上的定理 7.1，你可以回过头来再看它；</p> <p>2、上面的最优化问题怎么解？</p> <p>答：书本上 7.1.4 节”学习的对偶算法“就是在讲这一部分。这属于统计学习 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mn class="mjx-n"><mjx-c c="3"></mjx-c></mjx-mn></mjx-math></mjx-container> 要素的角度（模型、策略、方法）中的方法。我们为了看清”支持向量机“的全貌，可以暂时略过，这部分内容不好消化，要结合附录一起看，刚开始看的时候会渐渐忘了这个算法到底是在做什么，跑得原来越远，拉不回来了，这是我刚开始看这部分内容的状态，聪明的你应该比我好。</p> <p>3、只能解决严格线性可分的二分类问题，是不是太没用了。遇到不能线性可分的是不是就没辙了，多分类问题咋办？</p> <p>答：之所以先讨论严格的情况，是因为线性可分好做。其它非线性可分的情况，可以转化成线性可分的情况来做。想一想从一元线性回归到多元线性回归，通过构造多项式特征，最后也是用线性回归的算法来做的，道理是一样的。至于使用二分类问题问题解决多分类问题，机器学习中使用的思想有 ”OvO“ 与 ”OvR“，很多书籍上都有介绍，在这里就不展开了。</p> <p>写到这里，有一些概念我是没有提到，因为绝大多数将支持向量机的书籍都有讲，我罗列一下：支持向量、间隔、间隔边界、决策边界（即分离超平面），当然这个时候，你可以去看看函数间隔、几何间隔。这些概念其实都是见名知义的，如果你还比较模糊，不妨再翻翻书。</p> <h3 id="第-2-阶段-差一点线性可分的支持向量机"><a href="#第-2-阶段-差一点线性可分的支持向量机" class="header-anchor">#</a> 第 2 阶段：差一点线性可分的支持向量机</h3> <p>有的时候，我们会遇到一些离群点，如果要照顾到它们分类的正确性是得不偿失的。我们不会”捡了芝麻丢了西瓜“，就是这个道理。</p> <p><strong>理解松弛变量</strong></p> <p>那么，此时我们是怎么做的呢？<strong>对每一个数据引入一个松弛变量，这个变量对于分类正确且在间隔边界之外的数据而言为 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mn class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-math></mjx-container> ，如果在间隔边界之内，即使分类正确，也会有一个很小的值</strong>。</p> <p>理解这个思想可以对比于逻辑回归，对于逻辑回归算法而言，不管你分类多正确，你的损失函数都会计入一个很小的概率。而此时支持向量机不是：</p> <p>1、只要是分类正确的落在两个间隔边界之外的，认为是绝对安全的，因此不计损失；</p> <p>2、即使分类正确，但是落在两个间隔边界之内的，我们认为此时的预测有一定风险，这个风险就量化为松弛变量的值；</p> <p>3、分类错误的话，松弛变量的值就会大于 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-math></mjx-container> ，错得越离谱，这个值越大。</p> <p><strong>Soft Margin 和 SVM 的正则化</strong></p> <p>1、为了考虑到模型的泛化能力，我们放弃一些离群点，于是就有了 soft margin。
2、为什么要会引入 Soft Margin 呢？因为有可能“支撑向量”是离群点，这样就会使得我们的 margin 变得非常窄，于是我们就有下面的数学表示：</p>
{\rm s.t.}\quad y^{(i)}(w^Tx^{(i)}) \geq 1 - \zeta_i

<p>其中 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="3B6"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msub><mjx-mo space="4" class="mjx-n"><mjx-c c="2265"></mjx-c></mjx-mo><mjx-mn space="4" class="mjx-n"><mjx-c c="0"></mjx-c></mjx-mn></mjx-math></mjx-container>，这里 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="3B6"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math></mjx-container> 不是一个固定的数，并且我们不可能让 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="3B6"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math></mjx-container> 无限大，所以，我们在目标函数上限制</p>
{\rm min}\quad \frac{1}{2}||w||^2 + C\sum_{i=1}^{m} \zeta_{i}\\

<p><mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="C"></mjx-c></mjx-mi><mjx-munderover space="2" limits="false"><mjx-mo class="mjx-sop"><mjx-c c="2211"></mjx-c></mjx-mo><mjx-script style="vertical-align:-0.285em;"><mjx-TeXAtom size="s"><mjx-mi class="mjx-i"><mjx-c c="m"></mjx-c></mjx-mi></mjx-TeXAtom><mjx-spacer style="margin-top:0.284em;"></mjx-spacer><mjx-TeXAtom size="s"><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-script></mjx-munderover><mjx-msub space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="3B6"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-TeXAtom size="s"><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-TeXAtom></mjx-script></mjx-msub></mjx-math></mjx-container> 叫做正则化项，它是 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math></mjx-container> 正则化，同样，我们可以定义 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="L"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msub></mjx-math></mjx-container> 正则。</p> <p><strong>什么是惩罚系数 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="C"></mjx-c></mjx-mi></mjx-math></mjx-container></strong></p> <p>如何理解正则化：当 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="C"></mjx-c></mjx-mi></mjx-math></mjx-container> 越来越大的时候，我们的目标函数是求最小值，于是我们就逼迫<strong>正则化项</strong>应该越来越小，即容错空间越来越小，即此时的 Margin 是越来越 hard 的。</p> <p>反之，当 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="C"></mjx-c></mjx-mi></mjx-math></mjx-container> 越来越小的时候，正则化项就被忽略，因此容错空间就可以越来越大，margin 内部的点就可以越来越多，即朝着 soft 的方向发展。</p> <p>scikit-learn 中的 C 就是在这个位置。引入 soft margin 的原因是，让 SVM 模型对训练数据集有一定的容错能力，这样模型就不会对那些离群点敏感，于是泛化能力就更强了。</p> <p><mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="C"></mjx-c></mjx-mi></mjx-math></mjx-container> 其实我们并不陌生，我们在学习岭回归和 LASSO 回归的时候，知道可以在损失函数的后面加上一个尾巴，这个尾巴表示了模型的复杂程度，这个尾巴前面有一个系数，用于平衡损失函数和模型的复杂度：</p> <p><mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="C"></mjx-c></mjx-mi></mjx-math></mjx-container> 很大，说明模型复杂度占据了损失函数的主要部分，因此真的”损失“那部分就会淡化了，因此模型会变得简单，容易欠拟合；</p> <p><mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="C"></mjx-c></mjx-mi></mjx-math></mjx-container> 很小，极端情况那就跟没有一样，此时模型容易变得复杂，容易过拟合。</p> <p>这个道理在李航《统计学习方法》第 1 章介绍“策略”的部分，“结构风险 = 经验风险 + 正则化项”，正则化项又叫惩罚项，叫惩罚还好理解一点。</p> <p>这里 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="C"></mjx-c></mjx-mi></mjx-math></mjx-container> 的作用是一样的，为了权衡“最大间隔”和“对每一个数据引入的松弛变量”这两件事。如果我们对那个越过边界的点特别在意，“宁可错杀三千，不能放过一个”，这个 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="C"></mjx-c></mjx-mi></mjx-math></mjx-container> 就要设置得很大，让这个离群点尽量不越界或者越界的距离短一点。如果我们想要顾大局，牺牲个体，就可以把 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="C"></mjx-c></mjx-mi></mjx-math></mjx-container> 设置小一点。</p> <h3 id="从松弛变量的角度理解-svm-自带正则化"><a href="#从松弛变量的角度理解-svm-自带正则化" class="header-anchor">#</a> 从松弛变量的角度理解 SVM 自带正则化</h3> <p>引入了松弛变量以后，此时“差一点线性可分的支持向量机”所表达的最优化问题的数学表示式就跟“严格线性可分的支持向量机”差不多了，结构上一致，因此<strong>引入了松弛变量的线性支持向量机的问题就可以包括严格线性可分的支持向量机问题，因为其实只要引入的松弛变量都为 0，就是严格线性可分的支持向量机，两个问题合二为一了</strong>。</p> <p>还有一点好处，对于支持向量机而言，我们从来不谈“支持向量机”的正则化，这其实是在这一节介绍的“差一点线性可分的支持向量机”自带的效果。</p> <p>我们来看此时得到的数学表达式：</p>
{\rm \min_{w,b,\xi}} \qquad \cfrac{1}{2}||w||^2 + C\sum_{i=1}^N \xi_i\\
{\rm s.t.} \qquad y_i(w \cdot x_i+b) \geq 1 - \xi_i, \quad i = 1, 2, \cdots, N\\
\xi_i \ge0,\quad i = 1, 2, \cdots, N \quad\qquad

<p>目标函数从形式上看，前面的 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mfrac><mjx-frac><mjx-num><mjx-nstrut></mjx-nstrut><mjx-mrow size="s"><mjx-mpadded><mjx-block style="margin:0.896em 0 0.313em;"><mjx-mrow></mjx-mrow></mjx-block></mjx-mpadded><mjx-mstyle style="font-size:141.4%;"><mjx-TeXAtom><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-mstyle></mjx-mrow></mjx-num><mjx-dbox><mjx-dtable><mjx-line></mjx-line><mjx-row><mjx-den><mjx-dstrut></mjx-dstrut><mjx-mrow size="s"><mjx-mpadded><mjx-block style="margin:0.896em 0 0.313em;"><mjx-mrow></mjx-mrow></mjx-block></mjx-mpadded><mjx-mstyle style="font-size:141.4%;"><mjx-TeXAtom><mjx-mn class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-mstyle></mjx-mrow></mjx-den></mjx-row></mjx-dtable></mjx-dbox></mjx-frac></mjx-mfrac><mjx-mo class="mjx-n"><mjx-c c="|"></mjx-c></mjx-mo><mjx-mo class="mjx-n"><mjx-c c="|"></mjx-c></mjx-mo><mjx-mi class="mjx-i"><mjx-c c="w"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="|"></mjx-c></mjx-mo><mjx-msup><mjx-mo class="mjx-n"><mjx-c c="|"></mjx-c></mjx-mo><mjx-script style="vertical-align:0.363em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn></mjx-script></mjx-msup></mjx-math></mjx-container>  就是我们学习过的岭回归的表示形式，而后面的 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-munderover limits="false"><mjx-mo class="mjx-sop"><mjx-c c="2211"></mjx-c></mjx-mo><mjx-script style="vertical-align:-0.285em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="N"></mjx-c></mjx-mi><mjx-spacer style="margin-top:0.291em;"></mjx-spacer><mjx-TeXAtom size="s"><mjx-mi class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi><mjx-mo class="mjx-n"><mjx-c c="="></mjx-c></mjx-mo><mjx-mn class="mjx-n"><mjx-c c="1"></mjx-c></mjx-mn></mjx-TeXAtom></mjx-script></mjx-munderover><mjx-msub space="2"><mjx-mi noIC="true" class="mjx-i"><mjx-c c="3BE"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math></mjx-container> 是针对所有样本而言的，<mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msub><mjx-mi noIC="true" class="mjx-i"><mjx-c c="3BE"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.15em;"><mjx-mi size="s" class="mjx-i"><mjx-c c="i"></mjx-c></mjx-mi></mjx-script></mjx-msub></mjx-math></mjx-container> 是针对每一个样本在指定的一个距离<strong>间隔边界</strong>（注意是间隔边界，不是决策边界）的距离，可以看成是一种损失。目标函数的形式不就是”损失 + 正则化“的样子吗？</p> <p>这里的松弛变量的值书本上又叫它”合页损失“。</p> <p>这部分内容虽然占据了一定篇幅，但是很多都是和第 1 阶段相同，很多结论无非就是在限制条件那里多了个 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="C"></mjx-c></mjx-mi></mjx-math></mjx-container>。</p> <h3 id="第-3-阶段-线性不可分的支持向量机"><a href="#第-3-阶段-线性不可分的支持向量机" class="header-anchor">#</a> 第 3 阶段：线性不可分的支持向量机</h3> <p>终于到最后了。”和线性可分差距太远的时候“即这里对于”线性不可分的支持向量机“而言，我们的思路其实很简单，上面我们也提过，就是从”一元线性回归“到”多元线性回归“的思路，”通过构造特征升维“，”低维空间线性不可分，到高维空间就有可能线性可分“，李航老师的书上也用例子介绍了这个思路。</p> <h3 id="直观理解-低维空间线性不可分-到高维空间就有可能线性可分"><a href="#直观理解-低维空间线性不可分-到高维空间就有可能线性可分" class="header-anchor">#</a> 直观理解“低维空间线性不可分，到高维空间就有可能线性可分”</h3> <p>这一小节虽然一开始就在讲核技巧，整个章节也几乎都在介绍核技巧，但核技巧不是解决线性不可分的支持向量机问题的思想，它是一个具体的、可以操作的方法，核技巧是方法层面，不是思想层面，我们应该首先看到思想层面，因为它有时候更重要，而不应该被这个技巧、方法层面的东西蒙蔽了双眼。</p> <p>这里举一个可能不是很恰当的例子：一个学校来了两个老师，一个是普通二本师范院校刚刚毕业的学生 A，他是来工作的，一个是名牌大学的本科生 B，他来上课只是为了为考研赚一些生活费，他们的教学效果和受欢迎程度很可能是 A 更优，原因很简单：A 是来教书的，他选择了教育行业是热爱教学，经过 4 年的专业训练和学习，在教学技能和教学态度上很可能远远超过 B，而 B 有可能根本不喜欢教书，名牌大学毕业只是他的标签，他来教书只是为了贴补生活费，他的主要精力放在考研上。所以我们看待问题不能只看到这个问题吸引人的部分，有时要先看看它是用来干什么的。</p> <p>因此我们就可以在高维空间中，使用第 1 阶段和第 2 阶段介绍的线性可分或者近似线性可分的策略和方法来解决在高维空间线性可分的问题，进而解决在原始低维空间中线性不可分的问题。核心思想就是构造特征，转化。</p> <p>其实到这里支持向量机的主要框架就介绍完了，就这么简单。那么你要问我“核技巧”被你吃了吗？不是的，<strong>核技巧只是我们为了解决在高维空间中线性可分问题的时候使用的一个方法，因为它有一定技巧性，还有一点点神奇、神秘的色彩，是一个可以让我们偷懒的“捷径”，所以我们叫它“核技巧”</strong>。</p> <h3 id="核技巧-是技巧层面-而不是思想层面的东西"><a href="#核技巧-是技巧层面-而不是思想层面的东西" class="header-anchor">#</a> “核技巧”是技巧层面，而不是思想层面的东西</h3> <p>上面说了“线性不可分的支持向量机”首先是构造特征，把空间映射到高维空间，那么具体怎么做呢？</p> <p>首先“从低维空间到高维空间的映射”一定是非线性映射，才有可能把低维空间的超曲面“拉直”，问题来了，这个映射是什么？怎么找到这个映射？</p> <p>其实这个映射找到以后，我们要在高维空间中做运算，我们要意识到一点：在高维空间中做运算，其实是很消耗资源的。</p> <p>单单第一件事情其实就很不好办了，这个非线性映射是什么，那么多非线性映射，你怎么找。好在这件事情，伟大的数学家（计算机科学家）帮我们解决了。核技巧就帮我们一下子干了这两件事，核技巧给出了一个具体的样子，它虽然没有直接给出非线性映射的样子，但其实我们并不关心，我们只关心那个在高维空间中进行运算的结果（具体可以等到理解了对偶问题的算法再来理解），核技巧把它们合二为一，具体化了，我们剩下要做的只是调参，如果你的数据很干净，噪声很小，你可以设置参数，使得算法预测非常准确，这样即使过拟合，影响也不大，如果你的数据噪声很大，就得设置另一套参数，避免过拟合，这正是核技巧神奇、神秘的地方。</p> <p>“核技巧”把一个抽象的问题具体化，简单化，并且可以且容易操作。在这里还是强调一下，“核技巧”是方法层面，而不是思想层面的东西。处理非线性可分的问题，SVM 处理的思路是构造特征，使用样本在新的高维特征空间中线性可分。</p> <p>如果我们能够有一种方法轻松地解决低维空间中的非线性可分问题，或者我们轻松地找到了从低维空间到高维空间的非线性映射，并且在高维空间中进行计算毫不费事，那可能核函数（核技巧）就不为我们所知了。</p> <p>这里做一个阶段总结。</p> <p>1、SVM 是一个有约束的最优化问题；</p> <p>目标函数：</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>min</mi><mfrac><mrow><mn>1</mn></mrow><mrow><mn>2</mn></mrow></mfrac><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><mi>w</mi><mi mathvariant="normal">∣</mi><msup><mi mathvariant="normal">∣</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\min \frac{1}{2}||w||^2
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:1.32144em;"></span><span class="strut bottom" style="height:2.00744em;vertical-align:-0.686em;"></span><span class="base displaystyle textstyle uncramped"><span class="mop">min</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.686em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mord mathrm">2</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mord mathrm">∣</span><span class="mord mathrm">∣</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mord mathrm">∣</span><span class="mord"><span class="mord mathrm">∣</span><span class="vlist"><span style="top:-0.413em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord mathrm">2</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span></p> <p>使得：</p> <p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mo fence="true">{</mo><mtable><mtr><mtd><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>(</mo><mi>w</mi><mo>⋅</mo><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mi>b</mi><mo>)</mo><mo>≥</mo><mn>1</mn><mo separator="true">,</mo></mrow></mtd><mtd><mrow><mi mathvariant="normal">∀</mi><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn></mrow></mtd></mtr><mtr><mtd><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>(</mo><mi>w</mi><mo>⋅</mo><msub><mi>x</mi><mi>i</mi></msub><mo>+</mo><mi>b</mi><mo>)</mo><mo>≤</mo><mo>−</mo><mn>1</mn><mo separator="true">,</mo></mrow></mtd><mtd><mrow><mi mathvariant="normal">∀</mi><msub><mi>y</mi><mi>i</mi></msub><mo>=</mo><mo>−</mo><mn>1</mn></mrow></mtd></mtr></mtable></mrow></mrow><annotation encoding="application/x-tex">\begin{cases}
y_i(w\cdot x_i+b)\ge1,&amp; \forall y_i=1\\ 
y_i(w\cdot x_i+b)\le-1,&amp; \forall y_i=-1
\end{cases}
</annotation></semantics></math></span><span aria-hidden="true" class="katex-html"><span class="strut" style="height:1.75em;"></span><span class="strut bottom" style="height:3.0000299999999998em;vertical-align:-1.25003em;"></span><span class="base displaystyle textstyle uncramped"><span class="minner displaystyle textstyle uncramped"><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;"><span class="delimsizing size4">{</span></span><span class="mord"><span class="mtable"><span class="col-align-l"><span class="vlist"><span style="top:-0.6819999999999999em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mbin">⋅</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">+</span><span class="mord mathit">b</span><span class="mclose">)</span><span class="mrel">≥</span><span class="mord mathrm">1</span><span class="mpunct">,</span></span></span><span style="top:0.7579999999999999em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord displaystyle textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mopen">(</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mbin">⋅</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mbin">+</span><span class="mord mathit">b</span><span class="mclose">)</span><span class="mrel">≤</span><span class="mord">−</span><span class="mord mathrm">1</span><span class="mpunct">,</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="arraycolsep" style="width:1em;"></span><span class="col-align-l"><span class="vlist"><span style="top:-0.6819999999999999em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord displaystyle textstyle uncramped"><span class="mord mathrm">∀</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord mathrm">1</span></span></span><span style="top:0.7579999999999999em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="mord displaystyle textstyle uncramped"><span class="mord mathrm">∀</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:-0.03588em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord mathit">i</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="mrel">=</span><span class="mord">−</span><span class="mord mathrm">1</span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span></span></span></span></span></p> <p>2、用到的数学技巧：在感知机模型中，我们采用的是保留分子，固定分母；在 SVM 中，我们反过来，固定分子，保留分母。</p> <p>3、SVM 涉及到距离问题，所以要做特征归一化；</p> <p>4、为了解决非线性可分的问题，我们要升维度（<strong>低维空间不能线性可分，高维空间可以线性可分</strong>），但是升维度的时候带来了一个很大的问题，就是计算量大（维度灾难），核函数就帮我们解决了带来的计算量大的问题，我们可以<strong>直接在低维度空间中计算得到升维以后等价的效果</strong>。核函数的本质其实就是为了替换原来的  在高维空间中的计算；</p> <p>5、基本模型：定义在特征空间上的间隔最大的线性分类器，以获得更好的泛化能力。</p> <p>6、研究思路</p> <ul><li><p>线性可分支持向量机（硬间隔最大化）；</p></li> <li><p>线性支持向量机（软间隔最大化）：大概线性可分，丢弃少数离群点（噪声点）；</p></li> <li><p>非线性支持向量机；</p></li> <li><p>SVM 是一个判别模型（区别于先求出联合概率分布的生成模型），可以用于分类，也可以用于回归；</p></li> <li><p>支持向量机的损失函数，叫合页（hung）损失。</p></li></ul> <p>7、公式推导</p> <p>类标记与逻辑回归和感知机都不一样：决策函数 &gt;= 0 的时候，预测类别为 1；决策函数 &lt; 0 的时候，预测类别为 -1。</p> <h3 id="svm-的优点"><a href="#svm-的优点" class="header-anchor">#</a> SVM 的优点</h3> <p>1、解决小样本下机器学习问题；</p> <p>2、解决非线性问题；</p> <p>3、无局部极小值问题（相对于神经网络等算法）；</p> <p>4、可以很好的处理高维数据集；</p> <p>5、泛化能力比较强；</p> <p>6、模型依赖的支持向量比较少，说明它们都是非常精致的模型，消耗的内存少；</p> <p>7、一旦模型训练完成，预测阶段的速度非常快；</p> <p>8、模型只受边界线附近的点的影响，因此它们对于高维数据的学习效果非常好——即使训练比样本数量还要高的数据也没有问题，这是其他算法难以企及的；</p> <p>9、核技巧能够适用于不同类型的数据。</p> <h3 id="svm-的缺点"><a href="#svm-的缺点" class="header-anchor">#</a> SVM 的缺点</h3> <p>1、对于核函数的高维映射解释力不强，尤其是径向基函数；</p> <p>2、对缺失数据敏感；</p> <p>3、随着样本数量的增加，时间复杂度提升，计算成本高；</p> <p>4、训练的效果依赖于 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="C"></mjx-c></mjx-mi></mjx-math></mjx-container> 的选择，须要交叉验证来搜索，数据集大的时候，计算量也很大；</p> <p>5、进行概率解释比较困难，但 scikit-learn 支持计算概率。</p> <h3 id="svm-如何处理多分类问题"><a href="#svm-如何处理多分类问题" class="header-anchor">#</a> SVM 如何处理多分类问题</h3> <p>在机器学习的分类算法中，有些算法天生支持多分类问题，例如 k-近邻算法、朴素贝叶斯问题、决策树算法应用于分类。而有些分类算法最初是解决二分类问题的，要适用于多分类问题，需要一定的策略，其中，主要的策略有以下两种：</p> <p><strong>OVR（one vs rest）</strong></p> <p>假设我们的 target 有三个类 A、B、C，我们拿到一个新样本，这个时候我们做的事情是：</p> <p>1、A 类数据原封不动，将 B 类和 C 类数据归为一类，即非 A 类，针对 A 类和非 A 类数据，训练一个分类器；</p> <p>2、B 类数据原封不动，将 A 类和 C 类数据归为一类，即非 B 类，针对 B 类和非 B 类数据，训练一个分类器；</p> <p>3、C 类数据原封不动，将 A 类和 B 类数据归为一类，即非 C 类，针对 C 类和非 C 类数据，训练一个分类器。</p> <p>一共得到 3 个二分类器，将测试数据使用这 3 个二分类器进行分类投票，票数最多的那个类就作为这个测试数据最终的分类。</p> <p>可以看出，如果是 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi></mjx-math></mjx-container> 分类问题，OVR 策略就会训练出 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi></mjx-math></mjx-container> 个二分类器。</p> <p><strong>OVO（one vs one）</strong></p> <p>假设我们的 target 有三个类 A、B、C，我们拿到一个新样本，这个时候我们做的事情是：</p> <p>1、只拿出 A 类数据和 B 类数据，训练一个分类器；</p> <p>2、只拿出 A 类数据和 C 类数据，训练一个分类器；</p> <p>3、只拿出 B 类数据和 C 类数据，训练一个分类器。</p> <p>一共得到 3 个二分类器，将测试数据使用这 3 个二分类器进行分类投票，票数最多的那个类就作为这个测试数据最终的分类。</p> <p>可以看出，如果是 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-mi class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi></mjx-math></mjx-container> 分类问题，OVR 策略就会训练出 <mjx-container jax="CHTML" class="MathJax"><mjx-math class=" MJX-TEX"><mjx-msubsup><mjx-mi noIC="true" class="mjx-i"><mjx-c c="C"></mjx-c></mjx-mi><mjx-script style="vertical-align:-0.308em;"><mjx-mn size="s" class="mjx-n"><mjx-c c="2"></mjx-c></mjx-mn><mjx-spacer style="margin-top:0.18em;"></mjx-spacer><mjx-mi size="s" class="mjx-i"><mjx-c c="k"></mjx-c></mjx-mi></mjx-script></mjx-msubsup></mjx-math></mjx-container> 个二分类器，因此 OVO 策略的时间复杂度更高，但是更准确，因为，我们每次都是拿真实的两个类去训练，而不像 OVR 那样将类别的意义做了一些修改。</p> <h2 id="参考资料"><a href="#参考资料" class="header-anchor">#</a> 参考资料</h2> <p>[1] 李航. 统计学习方法（第 2 版）第 7 章“支持向量机”. 北京：清华大学出版社，2019.</p> <p>[2] 周志华. 机器学习（第 6 章“支持向量机”）. 北京：清华大学出版社.</p> <p>（本节完）</p> <hr> <p>以下为草稿，我自己留着备用，读者可以忽略，欢迎大家批评指正。</p> <p>后面还没有介绍的内容有：</p> <ul><li>如何求解第 1 部分提到的数学化以后的带约束的最优化问题；</li> <li>拉格朗日乘子法</li> <li>拉格朗日对偶问题</li> <li>KKT 条件</li> <li>核函数</li></ul> <p>当然，绝大部分介绍 SVM 的书籍在这些知识上已经讲解得很正确了，我只会谈一些直观理解和应用的部分。</p> <ul><li>仅仅使用一部分支持向量来做超平面的决策，无需依赖全部数据，效率高；</li> <li>SVM 模型的目标函数计算了距离，距离是对特征缩放敏感的，这一点类似于在 k 近邻算法中计算距离。</li> <li>SVM 用于回归；</li> <li>SVM 如何用于异常检测。</li> <li>软间隔最大化：那些参数和是不是支持向量机的关系：利用对偶互补条件，介绍合页损失</li> <li>落在软间隔之内的样本也是支持向量</li></ul> <p>求解：拉格朗日乘子法</p> <p>应用：最大熵模型，SVM，线性判别分析，主成分分析</p> <h3 id="参考资料-2"><a href="#参考资料-2" class="header-anchor">#</a> 参考资料</h3> <p>1、刘建平的文章</p> <p>支持向量机原理(一) 线性支持向量机
https://www.cnblogs.com/pinard/p/6097604.html</p> <p>scikit-learn 支持向量机算法库使用小结
https://www.cnblogs.com/pinard/p/6117515.html</p> <p>支持向量机高斯核调参小结
https://www.cnblogs.com/pinard/p/6126077.html</p> <p>2、<a href="https://www.bookstack.cn/read/hands_on_Ml_with_Sklearn_and_TF/docs-5.%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA.md" target="_blank" rel="noopener noreferrer">https://www.bookstack.cn/read/hands_on_Ml_with_Sklearn_and_TF/docs-5.%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA.md<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>3、拉格朗日对偶性：
http://www.hankcs.com/ml/lagrange-duality.html</p> <p>4、<a href="https://zhuanlan.zhihu.com/p/29604517" target="_blank" rel="noopener noreferrer">Python3《机器学习实战》学习笔记（八）：支持向量机原理篇之手撕线性SVM<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <p>5、SVM 核函数的理解：https://blog.csdn.net/u012328476/article/details/52382593</p> <p>6、关于核函数的参考资料：https://www.jiqizhixin.com/articles/2017-10-08</p></div> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">上次更新:</span> <span class="time">4/10/2021, 6:19:58 PM</span></div></footer> <!----> </main></div><div class="global-ui"><!----></div></div>
    <script src="/book/assets/js/app.a4355b0d.js" defer></script><script src="/book/assets/js/2.ba785ee6.js" defer></script><script src="/book/assets/js/48.9bb76138.js" defer></script>
  </body>
</html>
